from langchain.chains import ConversationChain
from langchain_openai import ChatOpenAI
from langchain.memory import ConversationBufferMemory
from dotenv import load_dotenv

load_dotenv()

llm = ChatOpenAI(model="gpt-4", max_tokens=500)
memory = ConversationBufferMemory(return_messages=True)

chat = ConversationChain(
    llm=llm,
    memory=memory,
    verbose=True
)

# PÄ™tla konwersacyjna
print("=== Rozmowa z agentem sterujÄ…cym dronem (wpisz 'exit' aby zakoÅ„czyÄ‡) ===\n")

while True:
    user_input = input("Operator: ")
    
    if user_input.lower() in ["exit", "quit"]:
        print("ZakoÅ„czono konwersacjÄ™.")
        break

    response = chat.predict(input=user_input)
    print(f"ðŸ¤– Agent: {response}\n")